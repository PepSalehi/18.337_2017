{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power method on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this continuation of lecture 2, we will see that having a good abstraction of hardware resources allows us to run the **same code** in parallel.\n",
    "\n",
    "\"Parallel computing will have made it when we never have to know any of the internal details.\" Alan Edelman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using parallel hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power_method (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function power_method(M, v)\n",
    "    T = eltype(v)\n",
    "    for i in 1:100\n",
    "        v = M*v        # repeatedly creates a new vector and destroys the old v\n",
    "        v ./= T(norm(v))\n",
    "    end\n",
    "    \n",
    "    return v, T(norm(M*v)) / T(norm(v))  # or  (M*v) ./ v\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPUArrays for calculations on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GPUArrays to abstract over GPU hardware. GPUArrays provides several backends;\n",
    "- threaded (pure Julia all the way down executed on the CPU)\n",
    "- opencl (mostly using Julia, using OpenCL to execute either on the GPU or the CPU)\n",
    "- cudanative (Julia all the way down, experimental)\n",
    "\n",
    "The great thing is that it tries to ensure that your code will run everywhere, even if no GPUs are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"GPUArrays\")\n",
    "# If you change your setup, run Pkg.build(\"GPUArrays\") to rediscover available backends\n",
    "# don't worry about errors in the setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using GPUArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GPUArrays.JLBackend,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPUArrays.active_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Device: Intel(R) Core(TM) i5-2520M CPU @ 2.50GHz\n",
       "            threads: 1\n",
       "             blocks: 1\n",
       "      global_memory: 8252.846080 mb\n",
       " free_global_memory: 401.354752 mb\n",
       "       local_memory: 0.000000 mb\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threaded Julia Context with:\n"
     ]
    }
   ],
   "source": [
    "if GPUArrays.is_backend_supported(:opencl) && GPUArrays.is_blas_supported(:CLBLAS)\n",
    "    # Always prefer CPUs\n",
    "    if isempty(GPUArrays.available_devices(GPUArrays.is_gpu))\n",
    "        GPUArrays.init(:opencl) # Allow start on CPU\n",
    "    else\n",
    "        GPUArrays.init(:opencl, GPUArrays.is_gpu)\n",
    "    end\n",
    "else\n",
    "    GPUArrays.init(:threaded) # To use this properly you have to set JULIA_NUM_THREADS=8 before starting Julia\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GPUArrays.jl` provides an easy way to create and manipulate arrays on the GPU. \n",
    "It is easy (although may be expensive!) to pass arrays backwards and forwards from the CPU to the GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a standard Julia matrix (on the CPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 2.0  1.0\n",
       " 1.0  1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [2 1; 1 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can copy this into an array on the GPU with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPUArray with ctx: Device: Intel(R) Core(TM) i5-2520M CPU @ 2.50GHz\n",
       "            threads: 1\n",
       "             blocks: 1\n",
       "      global_memory: 8252.846080 mb\n",
       " free_global_memory: 397.238272 mb\n",
       "       local_memory: 0.000000 mb\n",
       ": \n",
       "2×2 Array{Float64,2}:\n",
       " 2.0  1.0\n",
       " 1.0  1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threaded Julia Context with:\n"
     ]
    }
   ],
   "source": [
    "MM = GPUArray(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This calls a **constructor** of the `GPUArray` object, that constructs an array on the GPU by copying the data provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPUArray with ctx: Device: Intel(R) Core(TM) i5-2520M CPU @ 2.50GHz\n",
       "            threads: 1\n",
       "             blocks: 1\n",
       "      global_memory: 8252.846080 mb\n",
       " free_global_memory: 393.555968 mb\n",
       "       local_memory: 0.000000 mb\n",
       ": \n",
       "2-element Array{Float64,1}:\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threaded Julia Context with:\n"
     ]
    }
   ],
   "source": [
    "v = [1., 1]\n",
    "vv = GPUArray(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then multiply the matrix and vector **on the GPU**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPUArray with ctx: Device: Intel(R) Core(TM) i5-2520M CPU @ 2.50GHz\n",
       "            threads: 1\n",
       "             blocks: 1\n",
       "      global_memory: 8252.846080 mb\n",
       " free_global_memory: 393.506816 mb\n",
       "       local_memory: 0.000000 mb\n",
       ": \n",
       "2-element Array{Float64,1}:\n",
       " 3.0\n",
       " 2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MM * vv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the `*` operation indeed has a method defined to perform the matrix-vector multiplication and create the result as a new object (in fact, a $2 \\times 1$ matrix) on the GPU.\n",
    "\n",
    "We are thus now able to call `power_method` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threaded Julia Context with:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.850651, 0.525731], 2.618033988749895)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec, val = power_method(MM, vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPUArray with ctx: Device: Intel(R) Core(TM) i5-2520M CPU @ 2.50GHz\n",
       "            threads: 1\n",
       "             blocks: 1\n",
       "      global_memory: 8252.846080 mb\n",
       " free_global_memory: 384.659456 mb\n",
       "       local_memory: 0.000000 mb\n",
       ": \n",
       "2-element Array{Float64,1}:\n",
       " 0.850651\n",
       " 0.525731"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threaded Julia Context with:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "synchronize (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPUArrays.synchronize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the result of the calculation is indeed still an object on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Compare the time on GPU and CPU. Since execution on the GPU is asynchronous, it is necessary to synchronise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runGPU (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function runGPU(MM, vv)\n",
    "    vec, val = power_method(MM, vv)\n",
    "    GPUArrays.synchronize(vec) # wait for the GPU to finish\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.006286 seconds (3.75 k allocations: 168.751 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time runGPU(MM, vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.486059 seconds (100.29 k allocations: 5.121 MiB, 3.46% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.850651, 0.525731], 2.618033988749895)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time power_method(M, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10000\n",
    "M = rand(Float32, n, n)  # GPUs are much more efficient with Float32s\n",
    "M = (M + M')/2\n",
    "v = rand(Float32, n, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GPUArrays.GPUArray{Float64,2,Array{Float64,2},GPUArrays.JLBackend.JLContext}, GPUArrays.GPUArray{Float64,1,Array{Float64,1},GPUArrays.JLBackend.JLContext})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(MM),typeof(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12.118084 seconds (351.43 k allocations: 24.799 MiB, 1.27% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Float32[0.0099316; 0.0100577; … ; 0.0100161; 0.00998105], 5000.378f0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time power_method(M, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM = GPUArray(M)\n",
    "vv = GPUArray(v)\n",
    "\n",
    "#@time power_method(M, v);\n",
    "@time runGPU(MM, vv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeof(norm(MM*vv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my machine, the CPU version is much faster for small arrays, while the GPU version is 3 times faster for matrices of linear size $n=10000$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistributedArrays for large arrays spread across different processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Julia package [DistributedArrays.jl](https://github.com/JuliaParallel/DistributedArrays.jl) defines a `DArray` (\"distributed array\") type, which provides an abstraction that looks like a standard Julia array, but is spread across several different processors.\n",
    "\n",
    "Since modern desktops and laptops often have multiple cores, we can use this.\n",
    "\n",
    "First we allow Julia access to more processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addprocs(4)   # add cores to your Julia process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using DistributedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to create `DArray`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = drand(10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we really need to, we can find out where Julia is storing each piece of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M.indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the array was divided up into equal pieces on each of the four processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = drand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M * v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see that `*` has been defined for these objects, so once again we can just run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "power_method(M, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following averaging operator that we could call a random walk or averaging operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "averaging(n) = 0.5 * SymTridiagonal(zeros(n), ones(n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "averaging(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = 1:2:13\n",
    "averaging(7) * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "power_method(averaging(7), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have saved some memory by using a `SymTridiagonal` structure, we clearly are still storing far more information than we need to, since this is just \"0 on the diagonal and 0.5 on the super- and sub-diagonal\".\n",
    "\n",
    "We can define a new type in Julia to reflect this. We realise that we do **not actually need to store any information inside the \"matrix\"**. In fact, we will rather define a **linear operator**, just as we would really like to do in mathematics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type AveragingOp\n",
    "    # contains *no* information\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a \"dummy type\" that contains no information. It will be interesting because of \"what it can do\", i.e. the operations that we define that involve objects of this type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an object of this type, called `A`, with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = AveragingOp()  # default constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define what it means to multiply an object of this type by a vector. The simplest case would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Base.*  # necessary to overload *\n",
    "\n",
    "function *(A::AveragingOp, v::AbstractVector)\n",
    "    v  # just the identity operator\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which gives an identity operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = [1, 2, 43]\n",
    "A*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "power_method(A, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the actual averaging operation. It takes a vector and returns a new vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function *(A::AveragingOp, v::AbstractVector)\n",
    "    [ v[1];    # ; concatenates\n",
    "      [(v[i-1] + v[i+1])/2  for i in 2:length(v)-1];    # array comprehension\n",
    "      v[end] \n",
    "    ]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = (1:7).^2\n",
    "@show v\n",
    "A*v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `*` now works, we can again just reuse our some generic `power_method` implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "power_method(A, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could worry that `*` is not the correct notation. Mathematically, for an operator $\\mathcal{L}$ operating on a vector $\\mathbf{v}$, we might write $\\mathcal{L} \\mathbf{v}$, just using juxtaposition. Unfortunately, we are unable to use this notation in Julia.\n",
    "\n",
    "We could instead use a `⋅` for juxtaposition. Now that we have defined `*`, we can just do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Base.⋅\n",
    "A::AveragingOp ⋅ v = A * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A ⋅ v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even define $\\mathcal{L}(\\mathbf{v})$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(A::AveragingOp)(v) = A*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@which norm(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.3",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
