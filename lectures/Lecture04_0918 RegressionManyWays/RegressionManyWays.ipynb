{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "#gr()\n",
    "pyplot()\n",
    "#plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Table choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is all about finding patterns in data, so it is very reasonble to start with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some Data (try your own)\n",
    "x = [5,6.5,7,8]\n",
    "y = [10.1, 19.9, 30.1, 40.3]\n",
    "# plot(x,y,\n",
    "#     label=\"Y\", line=(7,:green), marker=(10,0.8,:red), xlims=(0,10), ylims=(0,50),\n",
    "#     xlabel=\"X\",ylabel=\"Y\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1. Just a matrix please. (No labels, no extras, simple.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = [x y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2. Data Frames: Inspired by the R universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "data2 = DataFrame(X=x,Y=y) # Upper Case X and Y are labels (not data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"CSV\")\n",
    "using CSV\n",
    "CSV.write(\"data.csv\", data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ";cat data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3. Indexed Tables (Treat data like array indices, knows type information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"IndexedTables\")\n",
    "using  IndexedTables.Table\n",
    "using IndexedTables\n",
    "data3 = Table(Columns(X=x),Columns(Y=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data3[6.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeof.([data1,data2,data3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.4. JuliaDB (Lots of bells and whistles, many files, parallelism, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"JuliaDB\")\n",
    "using JuliaDB:DTable\n",
    "using JuliaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data4 = distribute(data3, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data5 = loadfiles([\"data.csv\"], usecache=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeof(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data4[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select(data4,1=>i->i≥7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter(t->(t[1]>30),data4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.5 IterableTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#using IterableTables, DataTables, TypedTables # haven't investigated  much but looks very nice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Simple Line Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[So why is it called \"Regression\" anyway?](http://blog.minitab.com/blog/statistics-and-quality-data-analysis/so-why-is-it-called-regression-anyway) Dalton's original meaning not quite what it means today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.1 Linear Regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b, w =  linreg(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot()\n",
    "plot(x,y,\n",
    "    label=\"Y\", line=(4,:blue), marker=(3,0.8,:blue), xlims=(0,10), ylims=(0,50),\n",
    "    xlabel=\"X\",ylabel=\"Y\")\n",
    "plot!(x->w*x+b,xlims=(minimum(x)-.5,maximum(x)+.5), line=(4,:red), label=\"best fit line\")\n",
    "plot!(x->w*x+b, x ,marker=(3,0.8,:red), label=\"\" )\n",
    "for i = 1:length(x)\n",
    "    plot!([x[i],x[i]],[y[i],w*x[i]+b],line=(4,:green))\n",
    "end\n",
    "plot!(legend=:topleft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically equivalent Approaches <br>\n",
    "B.2 Linear Algebra Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = [ones(x) x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A'A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A\\y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(A'A)\\A'y  # normal equations usually not recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q,r = qr(A)\n",
    "r\\(q'y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[length(x) sum(x); sum(x) x⋅x] \\ [ sum(y) ; x⋅y ] # (A'A)\\A'y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.3 Basic Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = cov(x,y)/var(x) # same as (x.-mean(x))⋅(y.-mean(y))/sum(abs2,x.-mean(x))\n",
    "b = mean(y)-w*mean(x)\n",
    "b,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@which linreg(x,y) # essentially uses the above formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.4 optimization  (think machine learning) via the package optim.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Optim   # Julia all the way down\n",
    "loss(bw) = sum(abs2,bw[2]*x.+bw[1]-y) # uglyish\n",
    "optimize(loss,[0.0,0.0]).minimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.5 optimization with the package JuMP <br>\n",
    "Note not every julia function can be in @objective or @NLobjective\n",
    "but that would be the goal. See  [linear and quadratic objective Jump Notes](http://www.juliaopt.org/JuMP.jl/0.18/refexpr.html)  and [Nonlinear Jump Notes](http://www.juliaopt.org/JuMP.jl/0.18/nlp.html#syntax-notes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"Ipopt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using JuMP, Ipopt\n",
    "n = length(x)\n",
    "m = Model(solver=IpoptSolver(print_level=0))\n",
    "@variable(m,w)\n",
    "@variable(m,b)\n",
    "@objective(m, Min, sum((w*x[i]+b-y[i])^2 for i in 1:n))\n",
    "#@objective(m, Min,   sum(abs2,  w*x+b-y))\n",
    "solve(m)\n",
    "println( \" b = \", getvalue(b), \"w = \", getvalue(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.6 Generalized Linear Models <br>\n",
    "the very fancy statistical thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"GLM\")\n",
    "using GLM # Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm(@formula(Y~X), data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines above are obviously b and w\n",
    "We assume at the start X is known without error, b,w,σ are unknown and\n",
    "the real Y is distributed like  b+w*X+$\\sigma *$randn(),\n",
    "and the Y we have are samples from this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under these assumptions, if we fit many times, the b and w would be normal, with these predicted standard deviations.\n",
    "\n",
    "The third column is just the ratio of column 1 to column 2 , thus normalizing the situation to a standard normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the probability column is less than .05, we can reject the hypothesis that the intercept/slope is 0 at the 5 percent signficance level. What does this mean? It means we feel pretty good about our intercept and slope. If the probability is higher than .05 we can not reject the null hypothesis, meaning that we feel 0 for the intercept/slope could have been possible. In particular a 0 slope says that the dependent variable is not really statistically dependent after all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss(w,b,i) =(w*x[i]+b-y[i])^2  # loss due to point i\n",
    "Dloss(w,b,i) = 2*(w*x[i]+b-y[i])*[x[i];1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w,b = 0.0, 0.0\n",
    "for t=1:100000\n",
    "    η = .002  # there seems to be an art to picking these steplengths\n",
    "    i = rand(1:4)\n",
    "    d = Dloss(w,b,i)\n",
    "    w -= η * d[1]\n",
    "    b -= η * d[2]  \n",
    "end\n",
    " println(b,\" \",w)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss(w,b,i) =(w*χ[i]+b-y[i])^2  # loss due to point i\n",
    "Dloss(w,b,i) = 2*(w*χ[i]+b-y[i])*[χ[i];1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "μ = mean(x)\n",
    "σ = std(x)\n",
    "χ = (x-μ)/σ\n",
    "\n",
    "w,b = 0.0, 0.0\n",
    "for t=1:100000\n",
    "    η = .01  # there seems to be an art to picking these steplengths\n",
    "    i = rand(1:4)\n",
    "    d = Dloss(w,b,i)\n",
    "     w -= η * d[1]\n",
    "     b -= η * d[2] \n",
    "    ## instead fancy update rules like Adam ??\n",
    "   \n",
    "end\n",
    " println(b-w*μ/σ,\" \",w/σ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  D. KNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"Knet\")\n",
    "using Knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(w,x) = w[2]*x .+ w[1]\n",
    "loss(w,x,y) = sum(abs2, y - predict(w,x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lossgradient = grad(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train(w, data; lr=.1)\n",
    "    p=1\n",
    "    for (x,y) in data\n",
    "        println(\"This is pass $p\")\n",
    "        p+=1\n",
    "        dw = lossgradient(w, x, y)\n",
    "        for i in 1:length(w)\n",
    "            w[i] -= lr * dw[i]\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train([0.0,0.0],zip(x,y),lr=.01) # not enough data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [(x[i],y[i]) for i=1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train2(w, data; lr=.1)\n",
    "       for t in 1:10000\n",
    "          \n",
    "        (x,y) = data[rand(1:4)]\n",
    "        dw = lossgradient(w, x, y)\n",
    "            for i=1:length(w)\n",
    "            w[i] -= lr * dw[i]\n",
    "            #update(w, lossgradient(w,x,y), adam())\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2([0.0;0.0],data,lr=.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jon Malmaud explains why Julia+TensorFlow is way better than Python+Tensorflow\n",
    "[https://www.youtube.com/watch?v=MaCf1PtHEJo](https://www.youtube.com/watch?v=MaCf1PtHEJo)\n",
    "\n",
    "Why use Julia API when you can use Python API? <br>\n",
    "At 3:20 he explains three reasons: <br>\n",
    "1. Julia's Multiple Dispatch System <br>\n",
    "2. Julia's macro system <br>\n",
    "3. Julia's JIT compiler\n",
    "\n",
    "Namespace doesn't carry over. <br>\n",
    "Tensorflow models can be defined and Julia and sent over to Python. <br>\n",
    "Native Julia while loops look like Julia, not some weird TensorFlow thing. <br>\n",
    "Automatically imports new operations, no waiting. <br>\n",
    "\n",
    "Nico Jimenez says TensorFlow is too low level to be useful in some ways and too high level to be useful in other ways:\n",
    "[http://nicodjimenez.github.io/2017/10/08/tensorflow.html](http://nicodjimenez.github.io/2017/10/08/tensorflow.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 10.1\n",
       " 19.9\n",
       " 30.1\n",
       " 40.3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [5,6.5,7,8]\n",
    "y = [10.1, 19.9, 30.1, 40.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-02 11:11:03.716863: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-11-02 11:11:03.716894: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Session(Ptr{Void} @0x0000000121ac59d0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session=Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor X:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf X=placeholder(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFlow.Variables.Variable{Float32}(<Tensor W:1 shape=() dtype=Float32>, <Tensor W/Assign:1 shape=unknown dtype=Float32>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf W=get_variable([], Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFlow.Variables.Variable{Float32}(<Tensor b:1 shape=() dtype=Float32>, <Tensor b/Assign:1 shape=unknown dtype=Float32>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " @tf b=get_variable([], Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Y:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " @tf Y=X.*W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Y_obs:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " @tf Y_obs=placeholder(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Loss:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " @tf Loss=reduce_sum((Y.-Y_obs).^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientDescentOptimizer(α=0.001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer=train.GradientDescentOptimizer(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Group:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimizer=train.minimize(optimizer, Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(session, global_variables_initializer())\n",
    "for i in 1:20000\n",
    "    run(session, minimizer, Dict(X=>[5,6.5,7,8], Y_obs=>[10.1,19.9,30.1,40.3]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float32,1}:\n",
       " -41.7249\n",
       "  10.0896"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(session, [b, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:TensorBoard attempted to bind to port 6006, but it was already in use\n",
      "ERROR:tensorflow:TensorBoard attempted to bind to port 6007, but it was already in use\n"
     ]
    }
   ],
   "source": [
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:TensorBoard attempted to bind to port 6008, but it was already in use\n",
      "ERROR:tensorflow:TensorBoard attempted to bind to port 6009, but it was already in use\n"
     ]
    }
   ],
   "source": [
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
